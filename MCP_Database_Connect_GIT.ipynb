{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2fe714c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curl https://packages.microsoft.com/keys/microsoft.asc | apt-key add -\n",
    "# curl https://packages.microsoft.com/config/debian/11/prod.list | tee /etc/apt/sources.list.d/mssql-release.list\n",
    "# apt-get update\n",
    "# apt update\n",
    "# pip install pyodbc\n",
    "# apt install -y curl gnupg apt-transport-https unixodbc-dev jq postgresql-client\n",
    "# ACCEPT_EULA=Y apt install -y msodbcsql18\n",
    "# odbcinst -q -d | grep \"ODBC Driver 18\"\n",
    "# pip install anthropic\n",
    "# pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4342525d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from io import StringIO\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5c2860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MCP server main API\n",
    "\n",
    "def get_substring_between(text, delimiter, occurrence=1):\n",
    "    \"\"\"\n",
    "    Returns the substring between the N-th and (N+1)-th occurrence of a delimiter.\n",
    "    \n",
    "    Parameters:\n",
    "        text (str): The string to search in.\n",
    "        delimiter (str): The delimiter to search for.\n",
    "        occurrence (int): Which occurrence to consider (default is 1, i.e., between first and second delimiter).\n",
    "    \n",
    "    Returns:\n",
    "        str: Substring between the delimiters, or None if not found.\n",
    "    \"\"\"\n",
    "    parts = text.split(delimiter)\n",
    "    if len(parts) > occurrence:\n",
    "        return parts[occurrence]\n",
    "    return None\n",
    "\n",
    "def parse_markdown_table_no_unnamed(md_table: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Parse a Markdown-style table into a pandas DataFrame without creating 'Unnamed' columns.\n",
    "    \"\"\"\n",
    "    # Split lines and remove the separator line\n",
    "    lines = [line for line in md_table.strip().splitlines() if not line.startswith('|---')]\n",
    "    \n",
    "    # Split each line by '|' and strip whitespace\n",
    "    table_data = []\n",
    "    for line in lines:\n",
    "        # Remove leading/trailing pipes, then split\n",
    "        row = [cell.strip() for cell in line.strip().strip('|').split('|')]\n",
    "        table_data.append(row)\n",
    "    \n",
    "    # First row is headers\n",
    "    headers = table_data[0]\n",
    "    data = table_data[1:]\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(data, columns=headers)\n",
    "    df = drop_unnamed_columns(df)\n",
    "\n",
    "    return df\n",
    "\n",
    "def drop_unnamed_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Drops all columns from the DataFrame whose name contains 'Unnamed'.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame without columns containing 'Unnamed'.\n",
    "    \"\"\"\n",
    "    # Keep only columns that do NOT contain 'Unnamed'\n",
    "    df_clean = df.loc[:, ~df.columns.str.contains('^Unnamed', case=False)]\n",
    "    return df_clean\n",
    "\n",
    "def Connect_DB(username, password, server, port, database_name):\n",
    "    try:\n",
    "        # Connect to the SQL Server\n",
    "        conn = pyodbc.connect(\n",
    "        f'DRIVER={{ODBC Driver 18 for SQL Server}};'\n",
    "        f'SERVER={server};DATABASE={database_name};'\n",
    "        f'UID={username};PWD={password};;Encrypt=yes;TrustServerCertificate=yes;'\n",
    "        f'TlsVersion=1.1'\n",
    "    )\n",
    "\n",
    "        # cursor = conn.cursor()\n",
    "        # cursor.execute(\"select top 1 * from mcp_guests where e_mail = 'adossantos@purgatory.ski'\")  # Test query\n",
    "\n",
    "        # # Print results\n",
    "        # for row in cursor.fetchall():\n",
    "        #     print(row)\n",
    "\n",
    "        # conn.close()\n",
    "        print(\"Connection successful!\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error connecting to database:\", e)\n",
    "\n",
    "    return conn\n",
    "\n",
    "def Map_DB_tables_and_columns(conn):\n",
    "    \"\"\"\n",
    "    Returns a DataFrame with all tables and columns in the database.\n",
    "    \n",
    "    Parameters:\n",
    "        conn : pyodbc.Connection\n",
    "            An open connection to the MSSQL database.\n",
    "            \n",
    "    Returns:\n",
    "        pd.DataFrame with columns: 'table', 'column_name'\n",
    "    \"\"\"\n",
    "    query = \"\"\"\n",
    "    SELECT TABLE_NAME AS [table], COLUMN_NAME AS column_name\n",
    "    FROM INFORMATION_SCHEMA.COLUMNS\n",
    "    WHERE TABLE_CATALOG = DB_NAME()  -- current database\n",
    "    ORDER BY TABLE_NAME, ORDINAL_POSITION;\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_sql(query, conn)\n",
    "    # Returns df with columns: [table, column_name]\n",
    "\n",
    "    return df\n",
    "\n",
    "def DB_Close(conn):\n",
    "    conn.close()\n",
    "\n",
    "def Execute_Query(conn, QUERY):\n",
    "    \n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    cursor.execute(QUERY)\n",
    "    rows = cursor.fetchall()\n",
    "    column_values = [row[0] for row in rows]\n",
    "\n",
    "    return column_values\n",
    "\n",
    "def Check_Field_Is_Key(conn, Table_Name, Column_Name, THR=.98):\n",
    "    # This function checks whether a given column in a table in a DB connected with conn is a primary key or not.abs\n",
    "    # To do that it uses a THR of how many unique values are there in the column relative to it length (should be all unique)\n",
    "    # THR = .98 - The percentage that the len of unique values should be of the total len of the column\n",
    "\n",
    "    Field_Is_Key = 0\n",
    "    \n",
    "    # Get data from database\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    QUERY = f\"SELECT {Column_Name} FROM {Table_Name}\"\n",
    "    RESULT = Execute_Query(conn, QUERY)\n",
    "\n",
    "    # Check unique values\n",
    "    RESULT_SET = set(RESULT)\n",
    "    RATIO = len(RESULT_SET) / len(RESULT)\n",
    "    if RATIO>=THR:\n",
    "        Field_Is_Key = 1\n",
    "\n",
    "    return Field_Is_Key\n",
    "\n",
    "def Check_Table_Depedencies(conn, DB_Mapping_DF=None):\n",
    "    # This function runs through all tables of the database connected with conn and returns a DF of dependencies between tables\n",
    "    # via primary key (example: ID in a table)\n",
    "\n",
    "    if DB_Mapping_DF is None:\n",
    "        DB_Mapping_DF = Map_DB_tables_and_columns(conn)\n",
    "        Table_Names = DB_Mapping_DF['table'].unique()\n",
    "\n",
    "    Primary_Key_Columns_DICT = {}\n",
    "    Primary_Key_Columns_Counter = 0\n",
    "\n",
    "    print('Analyzing table columes...')\n",
    "\n",
    "    for ii, table_name in enumerate(Table_Names):\n",
    "        table_columns = list(DB_Mapping_DF[DB_Mapping_DF['table']==table_name]['column_name'])\n",
    "\n",
    "        for jj, column_name in enumerate(table_columns):\n",
    "            print(f'Analyzing table No.{ii+1} out of {len(Table_Names)} - column No.{jj+1} out of {len(table_columns)}', end='\\r')\n",
    "\n",
    "            if Check_Field_Is_Key(conn, table_name, column_name):\n",
    "                try:\n",
    "                    Primary_Key_Columns_DICT[table_name].append(column_name)\n",
    "                except:\n",
    "                    Primary_Key_Columns_DICT[table_name] = []\n",
    "                    Primary_Key_Columns_DICT[table_name].append(column_name)\n",
    "\n",
    "                Primary_Key_Columns_Counter += 1\n",
    "\n",
    "    print('\\nDONE.')\n",
    "    print(f'{Primary_Key_Columns_Counter}\\tPrimary key columns were found in {len((Primary_Key_Columns_DICT))} tables')\n",
    "\n",
    "    return Table_Names\n",
    "\n",
    "def pyodbc_rows_to_dataframe(cursor):\n",
    "    rows = cursor.fetchall()\n",
    "    if not rows:\n",
    "        return pd.DataFrame()\n",
    "    columns = [col[0] for col in cursor.description]\n",
    "    data = [tuple(row) for row in rows]  # ‚Üê critical conversion\n",
    "    return pd.DataFrame(data, columns=columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb2255d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection successful!\n"
     ]
    }
   ],
   "source": [
    "# Connect to DB\n",
    "username = \"shakudo\"\n",
    "password = \"6?jsV4Mb{&1)q34v\"\n",
    "server = \"63.158.251.204\"  # host,port\n",
    "port = 1433\n",
    "database_name = \"siriusware\"  # if known\n",
    "\n",
    "conn = Connect_DB(username, password, server, port, database_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd4fe94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example query: select all rows from a table\n",
    "# Table_Name = 'access'\n",
    "# query = f\"SELECT * FROM {Table_Name}\"\n",
    "\n",
    "# cursor.execute(query)\n",
    "\n",
    "# # Fetch all results\n",
    "# rows = cursor.fetchall()\n",
    "\n",
    "# print(f'{len(rows)} Rows retrieved')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d771c094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stored procedures\n",
    "\n",
    "STORED_PROC_DICT = {}\n",
    "STORED_PROC_DICT['Revenue'] = 'exec Shakudo_DMRGetRevenue @database=?, @group_no=?, @date_ini=?, @date_end=?'\n",
    "STORED_PROC_DICT['Payroll'] = 'exec Shakudo_DMRGetPayroll @resort=?, @date_ini=?, @date_end=?'\n",
    "STORED_PROC_DICT['Visits'] = 'exec Shakudo_DMRGetVists @resort=?, @date_ini=?, @date_end=?'\n",
    "STORED_PROC_DICT['Weather'] = 'exec Shakudo_GetSnow @resort=?, @date_ini=?, @date_end=?'\n",
    "\n",
    "# -- @resort = Snowbowl, Purgatory, Brian Head, Lee Canyon, Nordic Valley, Sipapu, Willammette\n",
    "# -- @date_ini/@date_end please pass with time: example for yesterday: @date_ini = '2025-10-10', @date_end = '2025-10-10 23:59:59'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104ba85a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Powderhouse', '', 'D5201', Decimal('6653.2800'))\n",
      "('Branded', '', 'D4056', Decimal('4377.1800'))\n",
      "(\"Purgy's\", '', 'D5208', Decimal('24593.8500'))\n",
      "('Purg Sports Resort', '', 'D4054', Decimal('11514.2900'))\n",
      "(\"Hoody's\", '', 'D5206', Decimal('1020.0000'))\n",
      "('Expert Edge', '', 'D4053', Decimal('3300.3200'))\n",
      "('Purg Sports Main Ave', '', 'D4055', Decimal('7684.0100'))\n",
      "('Waffle Cabin', '', 'D5205                    ', Decimal('1630.8800'))\n",
      "('Paradise', '', 'D5207', Decimal('7278.2300'))\n",
      "('Tickets', 'T100', 'D1500', Decimal('131810.6500'))\n",
      "('Ski School', '', 'D2000', Decimal('80298.1000'))\n",
      "('Child Care', '', 'D2200', Decimal('2000.0000'))\n",
      "('Rentals', '', 'D3000', Decimal('82114.5000'))\n",
      "(\"Dante's\", '', 'D5202', Decimal('9429.8100'))\n",
      "('Village Market Deli', '', 'D5209', Decimal('2712.9000'))\n",
      "len(rows) = 15\n"
     ]
    }
   ],
   "source": [
    "# Run a stored procedure\n",
    "\n",
    "# Create a cursor and execute the stored procedure\n",
    "cursor = conn.cursor()\n",
    "\n",
    "database = 'Purgatory'\n",
    "group_no = 46\n",
    "date_ini = datetime(2025, 3, 10, 0, 0, 0)\n",
    "date_end = datetime(2025, 3, 10, 23, 59, 59)\n",
    "# date_ini = '2025-03-10'\n",
    "# date_end = '2025-30-10 23:59:59'\n",
    "resort = 'Purgatory'\n",
    "\n",
    "# cursor.execute(STORED_PROC_DICT['Revenue'], (database, group_no, date_ini, date_end))\n",
    "# cursor.execute(STORED_PROC_DICT['Payroll'], (resort, date_ini, date_end))\n",
    "# cursor.execute(STORED_PROC_DICT['Visits'], (resort, date_ini, date_end))\n",
    "# cursor.execute(STORED_PROC_DICT['Weather'], (resort, date_ini, date_end))\n",
    "\n",
    "cursor.execute(\"exec Shakudo_DMRGetRevenue @database=?, @group_no=?, @date_ini=?, @date_end=?\", (database, group_no, date_ini, date_end))\n",
    "# cursor.execute(\"exec Shakudo_DMRGetPayroll @resort=?, @date_ini=?, @date_end=?\", (resort, date_ini, date_end))\n",
    "# cursor.execute(\"exec Shakudo_DMRGetVists @resort=?, @date_ini=?, @date_end=?\", (resort, date_ini, date_end))\n",
    "# cursor.execute(\"exec Shakudo_GetSnow @resort=?, @date_ini=?, @date_end=?\", (resort, date_ini, date_end))\n",
    "\n",
    "# 3. Fetch results\n",
    "rows = cursor.fetchall()\n",
    "\n",
    "for row in rows:\n",
    "    print(row)\n",
    "\n",
    "print(f'len(rows) = {len(rows)}')\n",
    "\n",
    "# 4. Clean up\n",
    "cursor.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5e9bce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a5f9cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY = \"\"\"\n",
    "declare @database nvarchar(20) = 'Snowbowl' -- Snowbowl, Brian, Lee Canyon, Purgatory, MCP, Sipapu, Nordic\n",
    "declare @group_no int = -1 -- necessary for shared databases: \n",
    "-- Database: Purgatory \n",
    "--46\t*PURGATORY               \n",
    "--54\t*HESPERUS                \n",
    "--59\t*SNOWCAT                 \n",
    "--67\t*SPIDER MOUNTAIN         \n",
    "--70\t*DMMA                    \n",
    "--71\t*WILLAMETTE              \n",
    "-- Database: MCP\n",
    "--9\t** PAJARITO              \n",
    "--10\t** SANDIA                \n",
    "--12\t** WILLAMETTE            \n",
    "--13\t** AZ SNOWBOWL (temporary, only used week of 4th July 2025)\n",
    "\n",
    "declare @date_ini datetime = '2024-03-05'\n",
    "declare @date_end datetime = '2025-07-05 23:59:59'\n",
    "\n",
    "SELECT\n",
    "d.title as DepartmentTitle,\n",
    "r.*\n",
    "FROM\n",
    "(\n",
    "\tselect \n",
    "\tp.user_code as account, \n",
    "\tp.user_code2 as department, \n",
    "\t--p.user_code3 as item, \n",
    "\tsum(revenue) as revenue\n",
    "\tfrom\n",
    "\t(\n",
    "\t\tselect t.resort, \n",
    "\t\tt.pr_ctr_1 as pr_ctr_no,\n",
    "\t\tsum(pcsplit_1) as revenue\n",
    "\t\tfrom transact t\n",
    "\t\twhere date_time between @date_ini and @date_end\n",
    "\t\tand department <> '**TRANS**'\n",
    "\t\tand t.resort = @database\n",
    "\t\tand t.pcsplit_1 <> 0\n",
    "\t\tand (\n",
    "\t\t\t\t@group_no = -1 OR \n",
    "\t\t\t\t(t.salespoint in (select salespoint from sp_link where resort = @database and group_no = @group_no))\n",
    "\t\t\t)\n",
    "\t\tgroup by t.resort, t.pr_ctr_1\n",
    "\n",
    "\t\tunion all\n",
    "\t\t\n",
    "\t\tselect t.resort, \n",
    "\t\tt.pr_ctr_2 as pr_ctr_no,\n",
    "\t\tsum(pcsplit_2) as revenue\n",
    "\t\tfrom transact t\n",
    "\t\twhere date_time between @date_ini and @date_end\n",
    "\t\tand department <> '**TRANS**'\n",
    "\t\tand t.resort = @database\n",
    "\t\tand t.pcsplit_2 <> 0\n",
    "\t\tand (\n",
    "\t\t\t\t@group_no = -1 OR \n",
    "\t\t\t\t(t.salespoint in (select salespoint from sp_link where resort = @database and group_no = @group_no))\n",
    "\t\t\t)\n",
    "\t\tgroup by t.resort, t.pr_ctr_2\n",
    "\n",
    "\t\tunion all\n",
    "\t\t\n",
    "\t\tselect t.resort, \n",
    "\t\tt.pr_ctr_3 as pr_ctr_no,\n",
    "\t\tsum(pcsplit_3) as revenue\n",
    "\t\tfrom transact t\n",
    "\t\twhere date_time between @date_ini and @date_end\n",
    "\t\tand department <> '**TRANS**'\n",
    "\t\tand t.resort = @database\n",
    "\t\tand t.pcsplit_3 <> 0\n",
    "\t\tand (\n",
    "\t\t\t\t@group_no = -1 OR \n",
    "\t\t\t\t(t.salespoint in (select salespoint from sp_link where resort = @database and group_no = @group_no))\n",
    "\t\t\t)\n",
    "\t\tgroup by t.resort, t.pr_ctr_3\n",
    "\t\t\n",
    "\t\tunion all\n",
    "\t\t\n",
    "\t\tselect t.resort, \n",
    "\t\tt.pr_ctr_4 as pr_ctr_no,\n",
    "\t\tsum(pcsplit_4) as revenue\n",
    "\t\tfrom transact t\n",
    "\t\twhere date_time between @date_ini and @date_end\n",
    "\t\tand department <> '**TRANS**'\n",
    "\t\tand t.resort = @database\n",
    "\t\tand t.pcsplit_4 <> 0\n",
    "\t\tand (\n",
    "\t\t\t\t@group_no = -1 OR \n",
    "\t\t\t\t(t.salespoint in (select salespoint from sp_link where resort = @database and group_no = @group_no))\n",
    "\t\t\t)\n",
    "\t\tgroup by t.resort, t.pr_ctr_4\n",
    "\t\t\n",
    "\t\tunion all\n",
    "\t\t\n",
    "\t\tselect t.resort, \n",
    "\t\tt.pr_ctr_5 as pr_ctr_no,\n",
    "\t\tsum(pcsplit_5) as revenue\n",
    "\t\tfrom transact t\n",
    "\t\twhere date_time between @date_ini and @date_end\n",
    "\t\tand department <> '**TRANS**'\n",
    "\t\tand t.resort = @database\n",
    "\t\tand t.pcsplit_5 <> 0\n",
    "\t\tand (\n",
    "\t\t\t\t@group_no = -1 OR \n",
    "\t\t\t\t(t.salespoint in (select salespoint from sp_link where resort = @database and group_no = @group_no))\n",
    "\t\t\t)\n",
    "\t\tgroup by t.resort, t.pr_ctr_5\n",
    "\t\t\n",
    "\t\tunion all\n",
    "\t\t\n",
    "\t\tselect t.resort, \n",
    "\t\tt.pr_ctr_6 as pr_ctr_no,\n",
    "\t\tsum(pcsplit_6) as revenue\n",
    "\t\tfrom transact t\n",
    "\t\twhere date_time between @date_ini and @date_end\n",
    "\t\tand department <> '**TRANS**'\n",
    "\t\tand t.resort = @database\n",
    "\t\tand t.pcsplit_6 <> 0\n",
    "\t\tand (\n",
    "\t\t\t\t@group_no = -1 OR \n",
    "\t\t\t\t(t.salespoint in (select salespoint from sp_link where resort = @database and group_no = @group_no))\n",
    "\t\t\t)\n",
    "\t\tgroup by t.resort, t.pr_ctr_6\n",
    "\t) t\n",
    "\tleft join prof_ctr p on t.resort = p.resort and t.pr_ctr_no = p.pr_ctr_no\n",
    "\twhere p.user_code >= '40000' and p.user_code <= '49999'\n",
    "\tgroup by p.user_code, p.user_code2 -- , p.user_code3 (item)\n",
    "\thaving sum(revenue) <> 0\n",
    ") r\n",
    "left join intacct.dbo.Department d on d.DepartmentId = r.department\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6e40fb9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'QUERY' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(Tables_Columns_MAPPING_df\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m5\u001b[39m))\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDONE\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m RESULT \u001b[38;5;241m=\u001b[39m Execute_Query(conn, \u001b[43mQUERY\u001b[49m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ii, item \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(RESULT):\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mii\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(item)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'QUERY' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Render the full tables for MCP (Alex email)\n",
    "DB_Map_Enable = 0\n",
    "if DB_Map_Enable:\n",
    "    print('Getting all tables and their column names into DF...', end='')\n",
    "    Tables_Columns_MAPPING_df = Map_DB_tables_and_columns(conn)\n",
    "    print(Tables_Columns_MAPPING_df.head(5))\n",
    "    print('DONE')\n",
    "\n",
    "RESULT = Execute_Query(conn, QUERY)\n",
    "for ii, item in enumerate(RESULT):\n",
    "    print(f'{ii}\\t{item} ({type(item)})')\n",
    "\n",
    "print(f'len(RESULT) = {len(RESULT)}')\n",
    "# df.to_csv('MCP_Datalake_Mapping.CSV')\n",
    "# print(df)\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32967b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close database connection\n",
    "DB_Close(conn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
